{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import numpy as np\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor\n",
    "from arcgis.features import GeoSeriesAccessor\n",
    "import pandas as pd\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.pivot_table(df, values='a', index='b', columns='c', aggfunc='sum', fill_value=0)\n",
    "# pd.DataFrame.spatial.from_featureclass(???)  \n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)  \n",
    "\n",
    "# gsa = arcgis.features.GeoSeriesAccessor(df['SHAPE'])  \n",
    "# df['AREA'] = gsa.area  # KNOW YOUR UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA values in Spatially enabled dataframes (ignores SHAPE column)\n",
    "def fill_na_sedf(df_with_shape_column, fill_value=0):\n",
    "    if 'SHAPE' in list(df_with_shape_column.columns):\n",
    "        df = df_with_shape_column.copy()\n",
    "        shape_column = df['SHAPE'].copy()\n",
    "        del df['SHAPE']\n",
    "        return df.fillna(fill_value).merge(shape_column,left_index=True, right_index=True, how='inner')\n",
    "    else:\n",
    "        raise Exception(\"Dataframe does not include 'SHAPE' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Outputs'):\n",
    "    os.makedirs('Outputs')\n",
    "    \n",
    "outputs = ['.\\\\Outputs', \"scratch.gdb\", 'hui_for_web.gdb']\n",
    "gdb = os.path.join(outputs[0], outputs[1])\n",
    "gdb2 = os.path.join(outputs[0], outputs[2])\n",
    "\n",
    "if not arcpy.Exists(gdb):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[1])\n",
    "\n",
    "if not arcpy.Exists(gdb2):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hui= r'.\\inputs\\housing_unit_inventory_2022.gdb\\housing_unit_inventory_2022'\n",
    "hui= r\".\\inputs\\housing_unit_inventory_2022_20240122.gdb\\housing_unit_inventory_2022\"\n",
    "t = r'.\\inputs\\Stations_Interchanges.gdb\\Interchanges_and_Stations'\n",
    "t_lyr = arcpy.MakeFeatureLayer_management(t, 't_lyr')\n",
    "parks = r\".\\inputs\\wcv_parks.shp\"\n",
    "trails = r\".\\inputs\\TrailsAndPathways_WFRCMAG.shp\"\n",
    "trails_lyr = arcpy.MakeFeatureLayer_management(trails, 'trails_lyr')\n",
    "centers = r\"E:\\Data\\Boundaries\\WC2050Centers.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to summarize h+t\n",
    "target_features = hui\n",
    "join_features = centers\n",
    "output_features = os.path.join(gdb, \"_00_hui_center_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "fields = ['AreaName']\n",
    "for f in fields:\n",
    "\n",
    "# field\n",
    "    fieldindex = fieldmappings.findFieldMapIndex(f)\n",
    "    fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "    fieldmap.mergeRule = 'first'\n",
    "    fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_COMMON\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_df = pd.DataFrame.spatial.from_featureclass(sj[0])\n",
    "# sj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_df = sj_df[['UNIT_ID', 'AreaName', 'AreaType']].copy()\n",
    "sj_df.columns = ['UNIT_ID', 'CENTER', 'CENTERTYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'parks'\n",
    "# copy = arcpy.conversion.FeatureClassToFeatureClass(hui, gdb, f'hui_near_{name}')\n",
    "# near_result = arcpy.analysis.Near(in_features=copy, near_features=parks, method='GEODESIC')\n",
    "# df_parks = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_parks = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "# df_parks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'trails'\n",
    "# copy = arcpy.conversion.FeatureClassToFeatureClass(hui, gdb, f'hui_near_{name}')\n",
    "# arcpy.SelectLayerByAttribute_management(trails_lyr, 'NEW_SELECTION', \"\"\"Status IN ('EXISTING', 'Existing', 'Current')\"\"\")\n",
    "# near_result = arcpy.analysis.Near(in_features=copy, near_features=trails_lyr, method='GEODESIC')\n",
    "# df_trails = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_trails = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "# df_trails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'frontrunner'\n",
    "# copy = arcpy.conversion.FeatureClassToFeatureClass(hui, gdb, f'hui_near_{name}')\n",
    "# arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Commuter Rail Station' AND Status = 'Current'\")\n",
    "# near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "# df_fr = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_fr = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "# df_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lightrail'\n",
    "# copy = arcpy.conversion.FeatureClassToFeatureClass(hui, gdb, f'hui_near_{name}')\n",
    "# arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Light Rail Station' AND Status = 'Current'\")\n",
    "# near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "# df_lr = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_lr = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "# df_lr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'brt'\n",
    "# copy = arcpy.conversion.FeatureClassToFeatureClass(hui, gdb, f'hui_near_{name}')\n",
    "# arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'BRT Stop' And (Status = 'Current' Or Status IS NULL)\")\n",
    "# near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "# df_brt = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_brt = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "# df_brt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'fwyexit'\n",
    "# copy = arcpy.conversion.FeatureClassToFeatureClass(hui, gdb, f'hui_near_{name}')\n",
    "# arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Interchange' AND Status = 'Current'\")\n",
    "# near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "# df_fwy = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_fwy = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "# df_fwy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert distance from meters to miles\n",
    "df_fr['DIST_FR'] = df_fr['NEAR_DIST']*.000621371\n",
    "df_lr['DIST_LR'] = df_lr['NEAR_DIST']*.000621371\n",
    "df_brt['DIST_BRT'] = df_brt['NEAR_DIST']*.000621371\n",
    "df_fwy['DIST_FWYE'] = df_fwy['NEAR_DIST']*.000621371\n",
    "df_parks['DIST_PARK'] = df_parks['NEAR_DIST']*.000621371\n",
    "df_trails['DIST_TRAIL'] = df_trails['NEAR_DIST']*.000621371\n",
    "\n",
    "df_fr['DIST_FR'] = round(df_fr['DIST_FR'], 2)\n",
    "df_lr['DIST_LR'] = round(df_lr['DIST_LR'], 2)\n",
    "df_brt['DIST_BRT'] = round(df_brt['DIST_BRT'], 2)\n",
    "df_fwy['DIST_FWYE'] = round(df_fwy['DIST_FWYE'], 2)\n",
    "df_parks['DIST_PARK'] = round(df_parks['DIST_PARK'], 2)\n",
    "df_trails['DIST_TRAIL'] = round(df_trails['DIST_TRAIL'], 2)\n",
    "\n",
    "df_fr = df_fr[['UNIT_ID', 'DIST_FR']].copy()\n",
    "df_lr = df_lr[['UNIT_ID', 'DIST_LR']].copy()\n",
    "df_brt = df_brt[['UNIT_ID', 'DIST_BRT']].copy()\n",
    "df_fwy = df_fwy [['UNIT_ID', 'DIST_FWYE']].copy()\n",
    "df_parks = df_parks[['UNIT_ID', 'DIST_PARK']].copy()\n",
    "df_trails = df_trails[['UNIT_ID', 'DIST_TRAIL']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\Housing-Unit-Inventory-Explorer\\\\python\\\\Outputs\\\\hui_for_web.gdb\\\\hui_2022_web_version'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hui_df = pd.DataFrame.spatial.from_featureclass(hui)\n",
    "hui_df = (hui_df.merge(sj_df, on='UNIT_ID', how='left') \n",
    "                .merge(df_fr, on='UNIT_ID', how='left') \n",
    "                .merge(df_lr, on='UNIT_ID', how='left')  \n",
    "                .merge(df_brt, on='UNIT_ID', how='left')\n",
    "                .merge(df_fwy, on='UNIT_ID', how='left')\n",
    "                .merge(df_parks, on='UNIT_ID', how='left')\n",
    "                .merge(df_trails, on='UNIT_ID', how='left')) \n",
    "\n",
    "# hui_sf = hui_df[hui_df['TYPE']== 'single_family'].copy()\n",
    "# hui_mf = hui_df[hui_df['TYPE']!= 'single_family'].copy()\n",
    "\n",
    "# hui_df2 = pd.concat([hui_sf, hui_mf])\n",
    "hui_df.spatial.to_featureclass(location=os.path.join(gdb2, 'hui_2022_web_version'),sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, February 23, 2024 10:03:57 AM\",\"Succeeded at Friday, February 23, 2024 10:04:17 AM (Elapsed Time: 19.80 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\hui_for_web.gdb\\\\hui_2022_pts_web_version'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.FeatureToPoint(os.path.join(gdb2, 'hui_2022_web_version'), os.path.join(gdb2, 'hui_2022_pts_web_version'), \"INSIDE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hui_df = pd.DataFrame.spatial.from_featureclass(hui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hui_df.hist(column='DUA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3245673af07dcc28bdd829afb187282e9288a1f8195a5928b70ecba6e5973721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
