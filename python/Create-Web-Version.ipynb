{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import numpy as np\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor\n",
    "from arcgis.features import GeoSeriesAccessor\n",
    "import pandas as pd\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.pivot_table(df, values='a', index='b', columns='c', aggfunc='sum', fill_value=0)\n",
    "# pd.DataFrame.spatial.from_featureclass(???)  \n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)  \n",
    "\n",
    "# gsa = arcgis.features.GeoSeriesAccessor(df['SHAPE'])  \n",
    "# df['AREA'] = gsa.area  # KNOW YOUR UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA values in Spatially enabled dataframes (ignores SHAPE column)\n",
    "def fill_na_sedf(df_with_shape_column, fill_value=0):\n",
    "    if 'SHAPE' in list(df_with_shape_column.columns):\n",
    "        df = df_with_shape_column.copy()\n",
    "        shape_column = df['SHAPE'].copy()\n",
    "        del df['SHAPE']\n",
    "        return df.fillna(fill_value).merge(shape_column,left_index=True, right_index=True, how='inner')\n",
    "    else:\n",
    "        raise Exception(\"Dataframe does not include 'SHAPE' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Outputs'):\n",
    "    os.makedirs('Outputs')\n",
    "    \n",
    "outputs = ['.\\\\Outputs', \"scratch.gdb\", 'hui_for_web.gdb']\n",
    "gdb = os.path.join(outputs[0], outputs[1])\n",
    "gdb2 = os.path.join(outputs[0], outputs[2])\n",
    "\n",
    "if not arcpy.Exists(gdb):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[1])\n",
    "\n",
    "if not arcpy.Exists(gdb2):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hui= r'.\\inputs\\housing_unit_inventory_2022.gdb\\housing_unit_inventory_2022'\n",
    "hui_wfrc = r\".\\inputs\\WFRC_Housing_Unit_Inventory_20240725.gdb\\housing_unit_inventory_2022\"\n",
    "hui_mag = r'.\\inputs\\MAG_Housing_Unit_Inventory_20240819.gdb\\housing_unit_inventory'\n",
    "hui_box_elder = r\".\\inputs\\WFRC_Housing_Unit_Inventory_20240725.gdb\\housing_unit_inventory_box_elder_2020\"\n",
    "hui_tooele = r\".\\inputs\\housing_unit_inventory_tooele_20241007.gdb\\housing_unit_inventory_2024\"\n",
    "t = r'.\\inputs\\transit_stations_and_interchanges.shp'\n",
    "t_lyr = arcpy.MakeFeatureLayer_management(t, 't_lyr')\n",
    "parks = r\".\\inputs\\wcv_parks.shp\"\n",
    "trails = r\".\\inputs\\TrailsAndPathways_WFRCMAG.shp\"\n",
    "trails_lyr = arcpy.MakeFeatureLayer_management(trails, 'trails_lyr')\n",
    "centers = r\"E:\\Data\\Boundaries\\WC2050Centers.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script arguments\n",
    "rerun_proximity_functions = False # enable this is proximity has recently been run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge housing datasets, simplify and recalculate UNIT_ID (some units may disappear)\n",
    "hui_merged = arcpy.management.Merge([hui_wfrc, hui_mag, hui_box_elder, hui_tooele], os.path.join(gdb, 'merged_hui')) \n",
    "hui = arcpy.cartography.SimplifyPolygon(hui_merged, os.path.join(gdb, 'simplified_hui'), \"POINT_REMOVE\", 2.5)\n",
    "arcpy.CalculateField_management(hui,\"UNIT_ID\",'!OBJECTID!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to summarize get the center name\n",
    "target_features = hui\n",
    "join_features = centers\n",
    "output_features = os.path.join(gdb, \"_00_hui_center_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "fields = ['AreaName']\n",
    "for f in fields:\n",
    "\n",
    "# field\n",
    "    fieldindex = fieldmappings.findFieldMapIndex(f)\n",
    "    fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "    fieldmap.mergeRule = 'first'\n",
    "    fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_COMMON\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")\n",
    "\n",
    "sj_df = pd.DataFrame.spatial.from_featureclass(sj[0])\n",
    "sj_df = sj_df[['UNIT_ID', 'AreaName', 'AreaType']].copy()\n",
    "sj_df.columns = ['UNIT_ID', 'CENTER', 'CENTERTYPE']\n",
    "sj_df['UNIT_ID'] = sj_df['UNIT_ID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'parks'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=parks, method='GEODESIC')\n",
    "    df_parks = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_parks = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_parks['UNIT_ID'] = df_parks['UNIT_ID'].astype('Int64')\n",
    "# df_parks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'trails'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(trails_lyr, 'NEW_SELECTION', \"\"\"Status IN ('EXISTING', 'Existing', 'Current')\"\"\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=trails_lyr, method='GEODESIC')\n",
    "    df_trails = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_trails = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_trails['UNIT_ID'] = df_trails['UNIT_ID'].astype('Int64')\n",
    "# df_trails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'frontrunner'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Commuter Rail Station' AND Status = 'Current'\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_fr = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_fr = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_fr['UNIT_ID'] = df_fr['UNIT_ID'].astype('Int64')\n",
    "# df_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lightrail'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Light Rail Station' AND Status = 'Current'\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_lr = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_lr = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_lr['UNIT_ID'] = df_lr['UNIT_ID'].astype('Int64')\n",
    "# df_lr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'brt'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'BRT Stop' And (Status = 'Current' Or Status IS NULL)\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_brt = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_brt = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_brt['UNIT_ID'] = df_brt['UNIT_ID'].astype('Int64')\n",
    "# df_brt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'fwyexit'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Interchange' AND Status = 'Current'\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_fwy = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_fwy = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_fwy['UNIT_ID'] = df_fwy['UNIT_ID'].astype('Int64')\n",
    "# df_fwy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert distance from meters to miles\n",
    "df_fr['DIST_FR'] = df_fr['NEAR_DIST']*.000621371\n",
    "df_lr['DIST_LR'] = df_lr['NEAR_DIST']*.000621371\n",
    "df_brt['DIST_BRT'] = df_brt['NEAR_DIST']*.000621371\n",
    "df_fwy['DIST_FWYE'] = df_fwy['NEAR_DIST']*.000621371\n",
    "df_parks['DIST_PARK'] = df_parks['NEAR_DIST']*.000621371\n",
    "df_trails['DIST_TRAIL'] = df_trails['NEAR_DIST']*.000621371\n",
    "\n",
    "df_fr['DIST_FR'] = round(df_fr['DIST_FR'], 2)\n",
    "df_lr['DIST_LR'] = round(df_lr['DIST_LR'], 2)\n",
    "df_brt['DIST_BRT'] = round(df_brt['DIST_BRT'], 2)\n",
    "df_fwy['DIST_FWYE'] = round(df_fwy['DIST_FWYE'], 2)\n",
    "df_parks['DIST_PARK'] = round(df_parks['DIST_PARK'], 2)\n",
    "df_trails['DIST_TRAIL'] = round(df_trails['DIST_TRAIL'], 2)\n",
    "\n",
    "df_fr = df_fr[['UNIT_ID', 'DIST_FR']].copy()\n",
    "df_lr = df_lr[['UNIT_ID', 'DIST_LR']].copy()\n",
    "df_brt = df_brt[['UNIT_ID', 'DIST_BRT']].copy()\n",
    "df_fwy = df_fwy [['UNIT_ID', 'DIST_FWYE']].copy()\n",
    "df_parks = df_parks[['UNIT_ID', 'DIST_PARK']].copy()\n",
    "df_trails = df_trails[['UNIT_ID', 'DIST_TRAIL']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr['UNIT_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "hui_df = pd.DataFrame.spatial.from_featureclass(hui[0])\n",
    "hui_df = (hui_df.merge(sj_df, on='UNIT_ID', how='left') \n",
    "                .merge(df_fr, on='UNIT_ID', how='left') \n",
    "                .merge(df_lr, on='UNIT_ID', how='left')  \n",
    "                .merge(df_brt, on='UNIT_ID', how='left')\n",
    "                .merge(df_fwy, on='UNIT_ID', how='left')\n",
    "                .merge(df_parks, on='UNIT_ID', how='left')\n",
    "                .merge(df_trails, on='UNIT_ID', how='left')) \n",
    "\n",
    "# clear memory\n",
    "# for df in [sj_df, df_fr, df_lr, df_brt, df_fwy, df_parks, df_trails]: del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hui_df[['APX_BLT_YR','BLT_YR2']].to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the date field for timeslider\n",
    "hui_df['APX_BLT_YR'] = hui_df['APX_BLT_YR'].astype('Int64')\n",
    "# hui_df['BLT_YR2'] = pd.to_datetime(hui_df['APX_BLT_YR'], format='%Y',  errors='coerce')\n",
    "hui_df.loc[hui_df['APX_BLT_YR'].isna() == True, 'APX_BLT_YR'] = 0\n",
    "hui_df['BLT_YR2'] = pd.to_datetime(hui_df['APX_BLT_YR'], format='%Y',  errors='coerce')\n",
    "# hui_df.loc[hui_df['APX_BLT_YR'] > 0, 'BLT_YR2'] = pd.to_datetime(hui_df['APX_BLT_YR'], format='%Y',  errors='coerce')\n",
    "\n",
    "# alter the built decade attribute\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1840) & (hui_df['APX_BLT_YR'] < 1850), 'BLT_DECADE'] = \"1840\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1850) & (hui_df['APX_BLT_YR'] < 1860), 'BLT_DECADE'] = \"1850\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1860) & (hui_df['APX_BLT_YR'] < 1870), 'BLT_DECADE'] = \"1860\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1870) & (hui_df['APX_BLT_YR'] < 1880), 'BLT_DECADE'] = \"1870\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1880) & (hui_df['APX_BLT_YR'] < 1890), 'BLT_DECADE'] = \"1880\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1890) & (hui_df['APX_BLT_YR'] < 1900), 'BLT_DECADE'] = \"1890\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1900) & (hui_df['APX_BLT_YR'] < 1910), 'BLT_DECADE'] = \"1900\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1910) & (hui_df['APX_BLT_YR'] < 1920), 'BLT_DECADE'] = \"1910\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1920) & (hui_df['APX_BLT_YR'] < 1930), 'BLT_DECADE'] = \"1920\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1930) & (hui_df['APX_BLT_YR'] < 1940), 'BLT_DECADE'] = \"1930\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1940) & (hui_df['APX_BLT_YR'] < 1950), 'BLT_DECADE'] = \"1940\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1950) & (hui_df['APX_BLT_YR'] < 1960), 'BLT_DECADE'] = \"1950\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1960) & (hui_df['APX_BLT_YR'] < 1970), 'BLT_DECADE'] = \"1960\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1970) & (hui_df['APX_BLT_YR'] < 1980), 'BLT_DECADE'] = \"1970\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1980) & (hui_df['APX_BLT_YR'] < 1990), 'BLT_DECADE'] = \"1980\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1990) & (hui_df['APX_BLT_YR'] < 2000), 'BLT_DECADE'] = \"1990\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 2000) & (hui_df['APX_BLT_YR'] < 2010), 'BLT_DECADE'] = \"2000\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 2010) & (hui_df['APX_BLT_YR'] < 2020), 'BLT_DECADE'] = \"2010\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 2020) & (hui_df['APX_BLT_YR'] < 2030), 'BLT_DECADE'] = \"2020\"\n",
    "hui_df.loc[hui_df['BLT_DECADE'].isin(['1840', '1850', '1860', '1870', '1880', '1890']) == True, 'BLT_DECADE'] = '1840-1890'\n",
    "hui_df.loc[hui_df['BLT_DECADE'].isin(['1900', '1910', '1920', '1930', '1940', '1950']) == True, 'BLT_DECADE'] = '1900-1950'\n",
    "\n",
    "hui_df.loc[hui_df['SUBTYPE'].isin(['single_family', 'single_family_adu']) == True, 'TYPE'] = 'single_family'\n",
    "hui_df.loc[hui_df['SUBTYPE'].isin(['single_family', 'single_family_adu']) == False, 'TYPE'] = 'multi_family'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAG has some data from 2025; remove\n",
    "hui_df = hui_df[hui_df['APX_BLT_YR'] < 2025].copy()\n",
    "\n",
    "# Remove MAG EVAL_DATE field\n",
    "del hui_df['EVAL_DATE']\n",
    "\n",
    "# delete fields added from simplify polygon tool\n",
    "del hui_df['InPoly_FID']\n",
    "del hui_df['MaxSimpTol']\n",
    "del hui_df['MinSimpTol']\n",
    "hui_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hui_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export polygon file\n",
    "hui_df.spatial.to_featureclass(location=os.path.join(gdb2, 'hui_web_version'),sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export points file\n",
    "arcpy.management.FeatureToPoint(os.path.join(gdb2, 'hui_web_version'), os.path.join(gdb2, 'hui_pts_web_version'), \"INSIDE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3245673af07dcc28bdd829afb187282e9288a1f8195a5928b70ecba6e5973721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
