{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import numpy as np\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor\n",
    "from arcgis.features import GeoSeriesAccessor\n",
    "import pandas as pd\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.pivot_table(df, values='a', index='b', columns='c', aggfunc='sum', fill_value=0)\n",
    "# pd.DataFrame.spatial.from_featureclass(???)  \n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)  \n",
    "\n",
    "# gsa = arcgis.features.GeoSeriesAccessor(df['SHAPE'])  \n",
    "# df['AREA'] = gsa.area  # KNOW YOUR UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA values in Spatially enabled dataframes (ignores SHAPE column)\n",
    "def fill_na_sedf(df_with_shape_column, fill_value=0):\n",
    "    if 'SHAPE' in list(df_with_shape_column.columns):\n",
    "        df = df_with_shape_column.copy()\n",
    "        shape_column = df['SHAPE'].copy()\n",
    "        del df['SHAPE']\n",
    "        return df.fillna(fill_value).merge(shape_column,left_index=True, right_index=True, how='inner')\n",
    "    else:\n",
    "        raise Exception(\"Dataframe does not include 'SHAPE' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Outputs'):\n",
    "    os.makedirs('Outputs')\n",
    "    \n",
    "outputs = ['.\\\\Outputs', \"scratch.gdb\", 'hui_for_web2.gdb']\n",
    "gdb = os.path.join(outputs[0], outputs[1])\n",
    "gdb2 = os.path.join(outputs[0], outputs[2])\n",
    "\n",
    "if not arcpy.Exists(gdb):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[1])\n",
    "\n",
    "if not arcpy.Exists(gdb2):\n",
    "    arcpy.CreateFileGDB_management(outputs[0], outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hui= r'.\\inputs\\housing_unit_inventory_2022.gdb\\housing_unit_inventory_2022'\n",
    "hui_wfrc = r\".\\inputs\\WFRC_Housing_Unit_Inventory_20240725.gdb\\housing_unit_inventory_2022\"\n",
    "hui_mag = r'.\\inputs\\MAG_Housing_Unit_Inventory_20240819.gdb\\housing_unit_inventory'\n",
    "hui_box_elder = r\".\\inputs\\WFRC_Housing_Unit_Inventory_20240725.gdb\\housing_unit_inventory_box_elder_2020\"\n",
    "hui_tooele = r\".\\inputs\\housing_unit_inventory_tooele_20241007.gdb\\housing_unit_inventory_2024\"\n",
    "hui_morgan = r\".\\inputs\\Morgan_Housing_Unit_Inventory_20241031.gdb\\housing_unit_inventory_2024\"\n",
    "t = r'.\\inputs\\transit_stations_and_interchanges.shp'\n",
    "t_lyr = arcpy.MakeFeatureLayer_management(t, 't_lyr')\n",
    "parks = r\".\\inputs\\wcv_parks.shp\"\n",
    "trails = r\".\\inputs\\TrailsAndPathways_WFRCMAG.shp\"\n",
    "trails_lyr = arcpy.MakeFeatureLayer_management(trails, 'trails_lyr')\n",
    "centers = r\".\\inputs\\Boundaries.gdb\\Centers\"\n",
    "cities = r\".\\inputs\\Boundaries.gdb\\Cities\"\n",
    "counties = r\".\\inputs\\Boundaries.gdb\\Counties\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script arguments\n",
    "rerun_proximity_functions = True # enable this is proximity has recently been run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages'>Start Time: Thursday, October 31, 2024 3:36:58 PM<br>Succeeded at Thursday, October 31, 2024 3:37:26 PM (Elapsed Time: 27.69 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\scratch.gdb\\\\simplified_hui'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge housing datasets, simplify and recalculate UNIT_ID (some units may disappear)\n",
    "hui_merged = arcpy.management.Merge([hui_wfrc, hui_mag, hui_box_elder, hui_tooele, hui_morgan], os.path.join(gdb, 'merged_hui')) \n",
    "hui = arcpy.cartography.SimplifyPolygon(hui_merged, os.path.join(gdb, 'simplified_hui'), \"POINT_REMOVE\", 2.5)\n",
    "arcpy.CalculateField_management(hui,\"UNIT_ID\",'!OBJECTID!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to summarize get the center name\n",
    "target_features = hui\n",
    "join_features = centers\n",
    "output_features = os.path.join(gdb, \"_00_hui_center_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "fields = ['AreaName']\n",
    "for f in fields:\n",
    "\n",
    "# field\n",
    "    fieldindex = fieldmappings.findFieldMapIndex(f)\n",
    "    fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "    fieldmap.mergeRule = 'first'\n",
    "    fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "center_sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_COMMON\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")\n",
    "\n",
    "center_sj_df = pd.DataFrame.spatial.from_featureclass(center_sj[0])\n",
    "center_sj_df = center_sj_df[['UNIT_ID', 'AreaName', 'AreaType']].copy()\n",
    "center_sj_df.columns = ['UNIT_ID', 'CENTER', 'CENTERTYPE']\n",
    "center_sj_df['UNIT_ID'] = center_sj_df['UNIT_ID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to summarize get the center name\n",
    "target_features = hui\n",
    "join_features = cities\n",
    "output_features = os.path.join(gdb, \"_00_hui_city_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "fields = ['NAME']\n",
    "for f in fields:\n",
    "\n",
    "# field\n",
    "    fieldindex = fieldmappings.findFieldMapIndex(f)\n",
    "    fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "    fieldmap.mergeRule = 'first'\n",
    "    fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "city_sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_COMMON\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")\n",
    "\n",
    "city_sj_df = pd.DataFrame.spatial.from_featureclass(city_sj[0])\n",
    "city_sj_df = city_sj_df[['UNIT_ID', 'NAME']].copy()\n",
    "city_sj_df.columns = ['UNIT_ID', 'CITY']\n",
    "city_sj_df['UNIT_ID'] = city_sj_df['UNIT_ID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spatial join to summarize get the center name\n",
    "target_features = hui\n",
    "join_features = counties\n",
    "output_features = os.path.join(gdb, \"_00_hui_county_sj\")\n",
    "\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "fieldmappings.addTable(target_features)\n",
    "fieldmappings.addTable(join_features)\n",
    "\n",
    "fields = ['NAME']\n",
    "for f in fields:\n",
    "\n",
    "# field\n",
    "    fieldindex = fieldmappings.findFieldMapIndex(f)\n",
    "    fieldmap = fieldmappings.getFieldMap(fieldindex)\n",
    "    fieldmap.mergeRule = 'first'\n",
    "    fieldmappings.replaceFieldMap(fieldindex, fieldmap)\n",
    "\n",
    "# run the spatial join\n",
    "county_sj = arcpy.SpatialJoin_analysis(target_features, join_features, output_features,'JOIN_ONE_TO_ONE', \"KEEP_COMMON\", \n",
    "                           fieldmappings, \"HAVE_THEIR_CENTER_IN\")\n",
    "\n",
    "county_sj_df = pd.DataFrame.spatial.from_featureclass(county_sj[0])\n",
    "county_sj_df = county_sj_df[['UNIT_ID', 'NAME']].copy()\n",
    "county_sj_df.columns = ['UNIT_ID', 'COUNTY']\n",
    "county_sj_df['UNIT_ID'] = county_sj_df['UNIT_ID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'parks'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=parks, method='GEODESIC')\n",
    "    df_parks = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_parks = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_parks['UNIT_ID'] = df_parks['UNIT_ID'].astype('Int64')\n",
    "# df_parks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'trails'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(trails_lyr, 'NEW_SELECTION', \"\"\"Status IN ('EXISTING', 'Existing', 'Current')\"\"\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=trails_lyr, method='GEODESIC')\n",
    "    df_trails = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_trails = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_trails['UNIT_ID'] = df_trails['UNIT_ID'].astype('Int64')\n",
    "# df_trails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'frontrunner'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Commuter Rail Station' AND Status = 'Current'\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_fr = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_fr = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_fr['UNIT_ID'] = df_fr['UNIT_ID'].astype('Int64')\n",
    "# df_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'lightrail'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Light Rail Station' AND Status = 'Current'\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_lr = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_lr = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_lr['UNIT_ID'] = df_lr['UNIT_ID'].astype('Int64')\n",
    "# df_lr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'brt'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'BRT Stop' And (Status = 'Current' Or Status IS NULL)\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_brt = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_brt = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_brt['UNIT_ID'] = df_brt['UNIT_ID'].astype('Int64')\n",
    "# df_brt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'fwyexit'\n",
    "if rerun_proximity_functions == True:\n",
    "    copy = arcpy.conversion.ExportFeatures(hui, os.path.join(gdb, f'hui_near_{name}'))\n",
    "    arcpy.SelectLayerByAttribute_management(t_lyr, 'NEW_SELECTION', \"SubMode = 'Interchange' AND Status = 'Current'\")\n",
    "    near_result = arcpy.analysis.Near(in_features=copy, near_features=t_lyr, method='GEODESIC')\n",
    "    df_fwy = pd.DataFrame.spatial.from_featureclass(near_result[0])\n",
    "df_fwy = pd.DataFrame.spatial.from_featureclass(os.path.join(gdb, f'hui_near_{name}'))\n",
    "df_fwy['UNIT_ID'] = df_fwy['UNIT_ID'].astype('Int64')\n",
    "# df_fwy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert distance from meters to miles\n",
    "df_fr['DIST_FR'] = df_fr['NEAR_DIST']*.000621371\n",
    "df_lr['DIST_LR'] = df_lr['NEAR_DIST']*.000621371\n",
    "df_brt['DIST_BRT'] = df_brt['NEAR_DIST']*.000621371\n",
    "df_fwy['DIST_FWYE'] = df_fwy['NEAR_DIST']*.000621371\n",
    "df_parks['DIST_PARK'] = df_parks['NEAR_DIST']*.000621371\n",
    "df_trails['DIST_TRAIL'] = df_trails['NEAR_DIST']*.000621371\n",
    "\n",
    "df_fr['DIST_FR'] = round(df_fr['DIST_FR'], 2)\n",
    "df_lr['DIST_LR'] = round(df_lr['DIST_LR'], 2)\n",
    "df_brt['DIST_BRT'] = round(df_brt['DIST_BRT'], 2)\n",
    "df_fwy['DIST_FWYE'] = round(df_fwy['DIST_FWYE'], 2)\n",
    "df_parks['DIST_PARK'] = round(df_parks['DIST_PARK'], 2)\n",
    "df_trails['DIST_TRAIL'] = round(df_trails['DIST_TRAIL'], 2)\n",
    "\n",
    "df_fr = df_fr[['UNIT_ID', 'DIST_FR']].copy()\n",
    "df_lr = df_lr[['UNIT_ID', 'DIST_LR']].copy()\n",
    "df_brt = df_brt[['UNIT_ID', 'DIST_BRT']].copy()\n",
    "df_fwy = df_fwy [['UNIT_ID', 'DIST_FWYE']].copy()\n",
    "df_parks = df_parks[['UNIT_ID', 'DIST_PARK']].copy()\n",
    "df_trails = df_trails[['UNIT_ID', 'DIST_TRAIL']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "hui_df = pd.DataFrame.spatial.from_featureclass(hui[0])\n",
    "\n",
    "# these are recomputed\n",
    "del hui_df['CITY']\n",
    "del hui_df['COUNTY']\n",
    "\n",
    "# MAG has some data from 2025; remove\n",
    "hui_df = hui_df[(hui_df['APX_BLT_YR'] < 2025) | (hui_df['APX_BLT_YR'].isna())].copy()\n",
    "\n",
    "# Remove MAG EVAL_DATE field\n",
    "del hui_df['EVAL_DATE']\n",
    "\n",
    "# delete fields added from simplify polygon tool\n",
    "del hui_df['InPoly_FID']\n",
    "del hui_df['MaxSimpTol']\n",
    "del hui_df['MinSimpTol']\n",
    "\n",
    "hui_df = (hui_df.merge(city_sj_df, on='UNIT_ID', how='left')\n",
    "                .merge(county_sj_df, on='UNIT_ID', how='left') \n",
    "                .merge(center_sj_df, on='UNIT_ID', how='left') \n",
    "                .merge(df_fr, on='UNIT_ID', how='left') \n",
    "                .merge(df_lr, on='UNIT_ID', how='left')  \n",
    "                .merge(df_brt, on='UNIT_ID', how='left')\n",
    "                .merge(df_fwy, on='UNIT_ID', how='left')\n",
    "                .merge(df_parks, on='UNIT_ID', how='left')\n",
    "                .merge(df_trails, on='UNIT_ID', how='left')) \n",
    "\n",
    "# clear memory\n",
    "# for df in [sj_df, df_fr, df_lr, df_brt, df_fwy, df_parks, df_trails]: del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the date field for timeslider\n",
    "hui_df['APX_BLT_YR'] = hui_df['APX_BLT_YR'].astype('Int64')\n",
    "# hui_df['BLT_YR2'] = pd.to_datetime(hui_df['APX_BLT_YR'], format='%Y',  errors='coerce')\n",
    "hui_df.loc[hui_df['APX_BLT_YR'].isna() == True, 'APX_BLT_YR'] = 0\n",
    "hui_df['BLT_YR2'] = pd.to_datetime(hui_df['APX_BLT_YR'], format='%Y',  errors='coerce')\n",
    "hui_df.loc[hui_df['APX_BLT_YR'] == 0, 'APX_BLT_YR'] = np.nan\n",
    "# hui_df.loc[hui_df['APX_BLT_YR'] > 0, 'BLT_YR2'] = pd.to_datetime(hui_df['APX_BLT_YR'], format='%Y',  errors='coerce')\n",
    "\n",
    "# alter the built decade attribute\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1840) & (hui_df['APX_BLT_YR'] < 1850), 'BLT_DECADE'] = \"1840\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1850) & (hui_df['APX_BLT_YR'] < 1860), 'BLT_DECADE'] = \"1850\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1860) & (hui_df['APX_BLT_YR'] < 1870), 'BLT_DECADE'] = \"1860\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1870) & (hui_df['APX_BLT_YR'] < 1880), 'BLT_DECADE'] = \"1870\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1880) & (hui_df['APX_BLT_YR'] < 1890), 'BLT_DECADE'] = \"1880\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1890) & (hui_df['APX_BLT_YR'] < 1900), 'BLT_DECADE'] = \"1890\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1900) & (hui_df['APX_BLT_YR'] < 1910), 'BLT_DECADE'] = \"1900\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1910) & (hui_df['APX_BLT_YR'] < 1920), 'BLT_DECADE'] = \"1910\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1920) & (hui_df['APX_BLT_YR'] < 1930), 'BLT_DECADE'] = \"1920\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1930) & (hui_df['APX_BLT_YR'] < 1940), 'BLT_DECADE'] = \"1930\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1940) & (hui_df['APX_BLT_YR'] < 1950), 'BLT_DECADE'] = \"1940\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1950) & (hui_df['APX_BLT_YR'] < 1960), 'BLT_DECADE'] = \"1950\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1960) & (hui_df['APX_BLT_YR'] < 1970), 'BLT_DECADE'] = \"1960\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1970) & (hui_df['APX_BLT_YR'] < 1980), 'BLT_DECADE'] = \"1970\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1980) & (hui_df['APX_BLT_YR'] < 1990), 'BLT_DECADE'] = \"1980\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 1990) & (hui_df['APX_BLT_YR'] < 2000), 'BLT_DECADE'] = \"1990\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 2000) & (hui_df['APX_BLT_YR'] < 2010), 'BLT_DECADE'] = \"2000\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 2010) & (hui_df['APX_BLT_YR'] < 2020), 'BLT_DECADE'] = \"2010\"\n",
    "hui_df.loc[(hui_df['APX_BLT_YR'] >= 2020) & (hui_df['APX_BLT_YR'] < 2030), 'BLT_DECADE'] = \"2020\"\n",
    "hui_df.loc[hui_df['BLT_DECADE'].isin(['1840', '1850', '1860', '1870', '1880', '1890']) == True, 'BLT_DECADE'] = '1840-1890'\n",
    "hui_df.loc[hui_df['BLT_DECADE'].isin(['1900', '1910', '1920', '1930', '1940', '1950']) == True, 'BLT_DECADE'] = '1900-1950'\n",
    "\n",
    "hui_df.loc[hui_df['SUBTYPE'].isin(['single_family', 'single_family_adu']) == True, 'TYPE'] = 'single_family'\n",
    "hui_df.loc[hui_df['SUBTYPE'].isin(['single_family', 'single_family_adu']) == False, 'TYPE'] = 'multi_family'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627573, 26)\n"
     ]
    }
   ],
   "source": [
    "print(hui_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID               Int64\n",
      "UNIT_ID                int32\n",
      "TYPE          string[python]\n",
      "SUBTYPE       string[python]\n",
      "IS_OUG        string[python]\n",
      "UNIT_COUNT             int32\n",
      "DUA                  Float64\n",
      "ACRES                Float64\n",
      "TOT_BD_FT2           Float64\n",
      "TOT_VALUE            Float64\n",
      "APX_BLT_YR             Int32\n",
      "BLT_DECADE    string[python]\n",
      "SUBCOUNTY     string[python]\n",
      "BLT_YR2       datetime64[ns]\n",
      "VINTAGE                Int32\n",
      "SHAPE               geometry\n",
      "CITY          string[python]\n",
      "COUNTY        string[python]\n",
      "CENTER        string[python]\n",
      "CENTERTYPE    string[python]\n",
      "DIST_FR              Float64\n",
      "DIST_LR              Float64\n",
      "DIST_BRT             Float64\n",
      "DIST_FWYE            Float64\n",
      "DIST_PARK            Float64\n",
      "DIST_TRAIL           Float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "hui_df['UNIT_ID'] = hui_df['UNIT_ID'].astype('int32')\n",
    "hui_df['UNIT_COUNT'] = hui_df['UNIT_COUNT'].astype('int32')\n",
    "hui_df['APX_BLT_YR'] = hui_df['APX_BLT_YR'].astype('Int32')\n",
    "print(hui_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Projects\\\\Housing-Unit-Inventory-Explorer\\\\python\\\\Outputs\\\\hui_for_web2.gdb\\\\hui_web_version'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export polygon file\n",
    "hui_df.spatial.to_featureclass(location=os.path.join(gdb2, 'hui_web_version'), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages'>Start Time: Thursday, October 31, 2024 4:37:06 PM<br>Succeeded at Thursday, October 31, 2024 4:37:30 PM (Elapsed Time: 24.06 seconds)<br></div><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result '.\\\\Outputs\\\\hui_for_web2.gdb\\\\hui_pts_web_version'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export points file\n",
    "arcpy.management.FeatureToPoint(os.path.join(gdb2, 'hui_web_version'), os.path.join(gdb2, 'hui_pts_web_version'), \"INSIDE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3245673af07dcc28bdd829afb187282e9288a1f8195a5928b70ecba6e5973721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
